<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Sun Hao">
    
    <title>
        
            深度学习方法探析——浅层神经网络 |
        
        SnSpace
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/Slogo.svg">
    
<link rel="stylesheet" href="/fontawesome/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/regular.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"snhao222.github.io","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","logo":"/images/Slogo.svg","favicon":"/images/Slogo.svg","avatar":"/images/Slogo.svg","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"S  n  S  p  a  c  e","font_color":null,"hitokoto":{"enable":false}},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block_tools":{"enable":true,"style":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.8"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/Slogo.svg">
                </a>
            
            <a class="logo-title" href="/">
               SnSpace
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">深度学习方法探析——浅层神经网络</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/Slogo.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Sun Hao</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-10-07 09:20:41</span>
        <span class="mobile">2022-10-07 09:20</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/Learning-Materials/">Learning Materials</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    

    
    
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h2 id="1-逻辑回归"><a href="#1-逻辑回归" class="headerlink" title="1.逻辑回归"></a>1.逻辑回归</h2><p>逻辑回归可以理解为不具备<em>hidden layer</em>(隐藏层)的神经网络，其模型如图1所示。逻辑回归能通过线性计算预测输入特征值对应的输出，其中的特征权重<strong><em>w</em></strong>和偏差<strong><em>b</em></strong>决定着预测的准确度，因此获得合适的<strong><em>w</em></strong>和<strong><em>b</em></strong>是此模型的重点。使用输入加权的原因可以从人的神经元中找到答案，图2是人的神经元模型，可能同时有多个电信号作用于神经元，当它们的加权和大于神经元的阈值时，其就会在轴突产生输出电信号，神经网络就是由此发展而来的。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片1.png">
</div>



<center>图1 逻辑回归模型</center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片2.png">
</div>

<center>图2 神经元模型</center>

<h3 id="1-1-梯度下降法逻辑回归"><a href="#1-1-梯度下降法逻辑回归" class="headerlink" title="1.1 梯度下降法逻辑回归"></a>1.1 梯度下降法逻辑回归</h3><p>利用给定的一组带标记的训练集进行代数运算获取<strong><em>w</em></strong>和<strong><em>b</em></strong>是一项艰巨的工作，甚至是难以完成的，人工智能的发展也因此一度停滞不前。梯度下降法的提出解决了这一问题，虽然其获得的可能不是最优解，但至少让这一过程有解。梯度下降法的思路是：初始随机选择参数，根据预测值与期望值的偏差反向传播误差，进而调整参数的大小。就像从山的任意位置沿着梯度的方向朝着谷底前进，谷底就是预测偏差最小的位置，也就是模型训练的目标点。表1列出了本文会用到的符号解释。</p>
<center> <b>表1 本文用到的符号及解释</b> </center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片3.png">
</div>


<p>当输入值多于一个时，需要程序循环多次以计算对应的预测值，但在编程时，大量使用for循环会极大影响程序执行速度。为了解决这个问题，我们尽量采用向量的形式表示各个值，应用python内嵌函数可以轻松地处理向量的运算，经过比较，向量形式比for循环形式快数百倍。因此，本文均采用向量形式进行计算。<br>逻辑回归的过程可以分为forward propagation (向前传播)和backward propagation(向后传播)两个过程。向前传播通过上面所述的过程计算当前参数对应预测值的代价(或损失)，向后传播采用链式法则计算总代价(或总损失)对各参数的偏导数，根据设定的学习率更新参数。之后重复前述操作，直到达到理想的代价或者迭代次数为止。<br>具体的逻辑回归模型训练过程如下：</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片4.png">
</div>


<h3 id="1-2-编程实现逻辑回归"><a href="#1-2-编程实现逻辑回归" class="headerlink" title="1.2 编程实现逻辑回归"></a>1.2 编程实现逻辑回归</h3><p>现通过python编程搭建逻辑回归模型实现“猫识别”，程序采用模块化方式编写，用到的函数如表2所示。本文采用可下载的h5文件数据集进行模型训练，也可采用CSV文件数据集。</p>
<center> <b>表2 “猫识别”程序用到的函数</b></center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片5.png">
</div>

<p>本文模型训练迭代10000次，学习率采用0.005。运行程序，可以看到总代价随着训练次数逐渐减小，如图3所示。</p>
<p>下面随意下载一张猫的图片交给程序进行预测，图4为交给程序的猫图片，程序对图片预测后输出该图片是猫的概率，若概率大于0.5则判定该图片有猫，并显示预测结果，如图5所示。可以看到，程序预测该图片有99.66%的概率为猫。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片6.png">
</div>

<center>图3 逻辑回归程序不同迭代次数的总代价</center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片7.png" style="zoom: 50%;">
</div>



<center>图4 预测图片（含猫）</center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片8.png">
</div>

<center>图5 预测结果（含猫）</center>

<p>为了测试程序不会把所有图片认定为猫，再对一不含猫的图片进行预测，如图6所示。预测结果如图6所示，程序预测该图片有33.74%的概率为猫，认为这不是一张含有猫的图片。可以看出，程序可以正确分辨有无猫在图片中。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片9.png" style="zoom: 50%;">
</div>

<center>图6 预测图片（不含猫）</center> 

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片10.png">
</div>


<center>图7 预测结果（不含猫）</center>

<p>经过多次测试，发现程序对正面较清晰的猫识别概率很高，有些情况下存在识别错误。另外，对于一些与猫相近的狗的正面照也存在识别为猫的情况。</p>
<h2 id="2-浅层神经网络"><a href="#2-浅层神经网络" class="headerlink" title="2.浅层神经网络"></a>2.浅层神经网络</h2><p>逻辑回归可以看为只有一层的神经网络，也可以理解为人脑的一个神经元，将多个逻辑回归中的单元叠起来就变成了神经网络，如图8所示。其中，输入层也称为第0层，因此下图的神经网络被称为2层神经网络。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片11.png">
</div>

<center>图8 神经网络模型</center>

<h3 id="2-1-神经网络的表示"><a href="#2-1-神经网络的表示" class="headerlink" title="2.1 神经网络的表示"></a><strong>2.1</strong> <strong>神经网络的表示</strong></h3><p>神经网络的节点数比逻辑回归多，需要对逻辑回归的向量形式做一定的调整。本文采用上标 [1]表示第1层神经网络，第0层的<strong><em>X</em></strong>可用<script type="math/tex">A^{[0]}</script><br>表示，<strong><em>w</em></strong>从之前的1维向量变为矩阵<strong><em>W</em></strong>，其中，为方便后续计算，已将对应的<strong><em>w</em></strong>进行转置，如(5)式所示。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片26.png" style="zoom:60%;">
</div>

<p>每层的输出<script type="math/tex">Z^{[i]}</script>可通过(6)式计算</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片27.png" style="zoom:60%;">
</div>

<p>其中，<script type="math/tex">A^{[0]}</script>相当于第0层的输入，即<strong><em>X</em></strong>。下面以第1层为例推导该过程的维度对应关系：</p>
<script type="math/tex; mode=display">
W^{[1]}X=\begin{bmatrix}w_1^{[1]T}\\w_2^{[1]T}\\...\\w_{n_{hidden}}^{[1]T}\end{bmatrix}\cdot\begin{bmatrix}\vdots&\vdots&\vdots&\vdots\\x_1&x_2&x_3&\vdots\\\vdots&\vdots&\vdots&\vdots\end{bmatrix}=\begin{bmatrix}\vdots&\vdots&\vdots&\vdots\\w_1^{[1]T}&w_2^{[1]T}&w_3^{[1]T}&\vdots\\\vdots&\vdots&\vdots&\vdots\end{bmatrix}=\begin{bmatrix}\vdots&\vdots&\vdots&\vdots\\z_1^{[1]}&z_2^{[1]}&z_3^{[1]}&\vdots\\\vdots&\vdots&\vdots&\vdots\end{bmatrix}=Z^{[1]}</script><h4 id="2-1-1-forward-propagation-正向传播"><a href="#2-1-1-forward-propagation-正向传播" class="headerlink" title="2.1.1 forward propagation(正向传播)"></a><strong>2.1.1</strong> <strong>forward propagation(</strong>正向传播<strong>)</strong></h4><p>只有2层的浅层神经网络的正向传播可由以下4个式子求得</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片12.png" style="zoom:67%;">
</div>

<h4 id="2-1-2-backward-propagation-反向传播"><a href="#2-1-2-backward-propagation-反向传播" class="headerlink" title="2.1.2 backward propagation(反向传播)"></a><strong>2.1.2</strong> <strong>backward propagation(</strong>反向传播<strong>)</strong></h4><p>反向传播可总结为以下6个公式 (输出层采用sigmoid函数作为激活函数)</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片13.png" style="zoom:67%;">
</div>

<p>其中，(11)、(12)、(13)、(15)和(16)式原理同(2)-(4)式，现对(14)式进行适当推导。运用链式法则，可得</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片14.png" style="zoom:67%;">
</div>

<p>其中，</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片15.png" style="zoom:67%;">
</div>

<p>综合(17)-(19)式以上各式可得</p>
<script type="math/tex; mode=display">
dZ^{[1]}=W^{[2]T}*g^{[1]'}(Z^{[1]})</script><h4 id="2-1-3-浅层神经网络训练过程"><a href="#2-1-3-浅层神经网络训练过程" class="headerlink" title="2.1.3 浅层神经网络训练过程"></a><strong>2.1.3</strong> <strong>浅层神经网络训练过程</strong></h4><p>具体的浅层神经网络训练过程如下(以2层为例)：</p>
<p> <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片16.png" style="zoom: 60%;"></p>
<h4 id="2-1-4-激活函数的选择"><a href="#2-1-4-激活函数的选择" class="headerlink" title="2.1.4 激活函数的选择"></a><strong>2.1.4</strong> <strong>激活函数的选择</strong></h4><p>神经网络需要非线性的激活函数，因为如果激活函数是线性的，那么无论有多少隐藏层，都可以看作是一组线性组合，那么都会浓缩为1层，这显然是毫无意义的。在逻辑回归中用到的是sigmoid函数，如图9(a)所示，然而另外一种非线性函数tanh在大多数情况是更受欢迎的，如图9(b)所示，它覆盖了-1到1的值域，这在神经网络中会取得更好的效果，但如果模型所解决的是一个二分类问题，期望得到的是0或1，可以考虑在输出层使用sigmoid函数。这两个函数都存在一个问题，当z太大或太小时斜率接近于0，这会导致学习饱和，所以可以采用ReLu函数或Leaky ReLu函数代替，如图9(c)、(d)所示，他们都可以保证z较大时不错的收敛速度。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片17.png" style="zoom:90%;">
</div>

<center>图9 几种激活函数 </center>

<p>前述计算过程中，激活函数<script type="math/tex">g(z)</script>的导数经常被用到，因此本文将几种激活函数的导数整理到表3中。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片18.png" style="zoom:100%;">
</div>



<h4 id="2-1-5-随机初始化"><a href="#2-1-5-随机初始化" class="headerlink" title="2.1.5 随机初始化"></a>2.1.5 随机初始化</h4><p>训练神经网络时，权重随机初始化是十分重要的。当把权重<strong><em>W</em></strong>全部初始化为0时，同层的隐藏单元计算着同一个函数，他们对输出的影响也全部相同，无论经过多少次迭代他们都计算着相同的函数。也就是说，这和只有一个隐藏单元没有任何差别。为了解决这一问题，我们应当将<strong><em>W</em></strong>随机初始化，而<strong><em>b</em></strong>没有这个问题，可以将其初始化为0。</p>
<h3 id="2-2-编程实现浅层神经网络"><a href="#2-2-编程实现浅层神经网络" class="headerlink" title="2.2 编程实现浅层神经网络"></a><strong>2.2 编程实现浅层神经网络</strong></h3><p>现编程搭建只有一个隐藏层的浅层神经网络，隐藏层设置5个节点，用到的函数如表4所示。</p>
<center><b>表4 浅层神经网络用到的函数</b> </center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片19.png" style="zoom:100%;">
</div>


<p>为了方便比较，本文采用与逻辑回归程序相同的数据集进行训练，迭代次数同为10000次，总代价的变化如图10所示。可以发现，相同的迭代次数下，浅层神经网络比逻辑回归单节点网络的代价0.035704要小。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片20.png" style="zoom:100%;">
</div>

<center>图10 浅层神经网络程序不同迭代次数的总代价</center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片21.png" style="zoom:67%;">
</div> 

<center>图11 预测图片（含猫）</center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片22.png" style="zoom:100%;">
</div>

<center>图12 预测结果（含猫）</center>

<p>现使用与逻辑回归程序相同的两张图片对浅层神经网络进行测试。如图11所示，程序预测该图片有99.51%的概率为猫图片，相比逻辑回归单节点99.66%的概率略有降低，但两种情况下预测的概率都接近100%，可以认为识别效果都十分不错，并不能看出优劣。为了更加清晰地比较两种模型，我们选取一张不太标准的猫图片进行识别，如图13所示。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片23.png" style="zoom:67%;">
</div>

<center>图13 非标准含猫图片</center>

<p>逻辑回归的单节点模型预测的结果如图14所示，浅层神经网络预测的结果如图15所示。</p>
<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片24.png" style="zoom:100%;">
</div>

<center>图14 逻辑回归单节点模型预测结果图 </center>

<div align="center">
    <img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片25.png" style="zoom:100%;">
</div>

<center>图15 浅层神经网络预测结果 </center>

<p>可以看到，浅层神经网络的预测结果比单节点模型概率高8.86%，浅层神经网络的预测能力更强。</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li>Post title：深度学习方法探析——浅层神经网络</li>
        <li>Post author：Sun Hao</li>
        <li>Create time：2022-10-07 09:20:41</li>
        <li>
            Post link：https://snhao222.github.io/2022/10/07/深度学习方法探析——浅层神经网络/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/10/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习方法探析——深层神经网络</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
    <div class="valine-container">
        <script 
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script >
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'AIhtvUXrzUWmPIOmYNjrGExW-gzGzoHsz',
                    appKey: 'e4HGIfsWiHCnIXco4g7xtuAA',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: 'Add your comments',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Sun Hao';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('false') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2022</span> -
            
            2022
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Sun Hao</a>
            
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme
            &nbsp;
            <a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.8</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-up-right-and-down-left-from-center"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-text">1.逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-text">1.1 梯度下降法逻辑回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-text">1.2 编程实现逻辑回归</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">2.浅层神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="nav-text">2.1 神经网络的表示</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-forward-propagation-%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-text">2.1.1 forward propagation(正向传播)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-backward-propagation-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-text">2.1.2 backward propagation(反向传播)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-3-%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-text">2.1.3 浅层神经网络训练过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-4-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-text">2.1.4 激活函数的选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-5-%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-text">2.1.5 随机初始化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">2.2 编程实现浅层神经网络</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block-tools.js"></script>





<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
