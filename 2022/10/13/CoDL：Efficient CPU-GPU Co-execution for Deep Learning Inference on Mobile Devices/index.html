<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Sun Hao">
    
    <title>
        
            CoDL：Efficient CPU-GPU Co-execution for Deep Learning Inference on Mobile Devices |
        
        SnSpace
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/Slogo.svg">
    
<link rel="stylesheet" href="/fontawesome/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/regular.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"snhao222.github.io","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","logo":"/images/Slogo.svg","favicon":"/images/Slogo.svg","avatar":"/images/HeadImage.svg","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"S  n  S  p  a  c  e","font_color":null,"hitokoto":{"enable":false}},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block_tools":{"enable":true,"style":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.8"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/Slogo.svg">
                </a>
            
            <a class="logo-title" href="/">
               SnSpace
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">CoDL：Efficient CPU-GPU Co-execution for Deep Learning Inference on Mobile Devices</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/HeadImage.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Sun Hao</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-10-13 15:31:49</span>
        <span class="mobile">2022-10-13 15:31</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/Paper-Notes/">Paper Notes</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <blockquote>
<p> 来        源：MobiSys ‘22: Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and ServicesJune 2022 Pages 209–221<a class="link" target="_blank" rel="noopener" href="https://doi.org/10.1145/3498361.3538932">https://doi.org/10.1145/3498361.3538932<i class="fas fa-external-link-alt"></i></a></p>
<p> 原文速递：<a href="./CoDL efficient CPU-GPU co-execution for deep learning inference on mobile devices.pdf" title="点击直接下载原文">CoDL：Efficient CPU-GPU Co-execution for Deep Learning Inference on Mobile Devices</a></p>
</blockquote>
<h2 id="1-Background-amp-Motivation"><a href="#1-Background-amp-Motivation" class="headerlink" title="1.Background &amp; Motivation"></a>1.Background &amp; Motivation</h2><p>当前，深度学习已经成为众多移动应用的支柱。由于隐私性，网络弹性和云计算开销上的优势，在边缘设备上进行推理成为一种趋势。然而，边缘设备的性能有限，只有在推理轻量小模型时才能获得能够容忍的推理速度，比如在移动处理器上运行YOLO目标检测网络具有超200ms的延时。为了能够在移动设备上缩短大模型推理的时延，该文致力于同时利用移动设备上的CPU和GPU来加速推理。该方案可行的两个主要原因是：</p>
<blockquote>
<p>1）与运行速度比CPU快一个数量级的服务器GPU不同，移动CPU和GPU在DL推理上具有近似的性能，因此可以进行并行推理；</p>
<p>2）与服务器上CPU和GPU有独立的内存不同，移动设备的CPU和GPU具有统一的内存空间，可以避免不同内存间的数据复制。</p>
</blockquote>
<p>然而，现有的协同执行系统存在以下问题：</p>
<blockquote>
<p>1）在不同的处理器间使用相同的数据类型。统一的数据类型在多种处理器上的处理效率是不同的，如图1，在Adreno GPU上使用Image类型的数据比buffer类型更高效；</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片1.png" style="zoom: 60%;">
</div>

<center>图1 使用buffer和image数据类型进行3×3卷积的时延对比</center>

<p>2）处理器间的数据传输开销是不可忽视的，特别是对于小尺寸的算子。如图2，CPU和GPU并行推理存在数据类型转换（DT）、数据映射（M）、同步（Pre-sync &amp; Post-sync）和数据解映射四种额外开销。对于小算子，额外开销可能会占据总开销的主要部分（图3）；</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片2.png" style="zoom: 60%;">
</div>

<center>图2 CPU-GPU协同执行的时延组成</center>

<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片3.png" style="zoom: 60%;">
</div>

<center>图3 形状为<52，52，256，128>的1×1卷积的计算时延和数据共享开销</52，52，256，128></center>

<p>3）平衡的工作负载分割需要轻量且准确的时延预测器。现有协同执行系统大都使用轻量的时延预测模型去指导工作负载的切分，然而如表1所示，轻量的模型虽然适合于在线预测，但准确性很差（&lt;10%），这是由于执行的时延并不是FLOPs的线性函数，而是受平台特性影响的（图4）。同时，还有一些工作致力于准确的时延预测，例如nn-Meter，但由于缺乏对部署平台特性的知识，其获得高精度的代价是需要运行大规模模型，不适合在移动设备上部署。</p>
<center><b>表1 两种时延预测器的±10%准确度和模型尺寸</b></center>

<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片5.png" style="zoom: 60%;">
</div>

<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片4.png" style="zoom: 60%;">
</div>

<center>图4 （a）GPU（b）CPU对FLOPs增加表现出的非线性</center>

</blockquote>
<h2 id="2-Contributions"><a href="#2-Contributions" class="headerlink" title="2. Contributions"></a>2. Contributions</h2><blockquote>
<p>1）深入分析CPU+GPU协同推理的性能瓶颈；</p>
<p>2）提出CPU和GPU间的多类型数据共享机制，通过设计多维分割和算子链来减小数据共享开销；</p>
<p>3）提出轻量的准确时延预测方法；</p>
<p>4）在设备上部署端到端的CoDL框架，验证其相较于SOTA方案的优点。</p>
</blockquote>
<h2 id="3-Design-Details"><a href="#3-Design-Details" class="headerlink" title="3.Design Details"></a>3.Design Details</h2><p>CoDL的系统设计遵循三个原则：</p>
<blockquote>
<p>1）充分利用每个处理器的计算能力；</p>
<p>2）最小化数据共享的额外开销；</p>
<p>3）多种处理器间的工作负载最优分割。</p>
</blockquote>
<p>CoDL的系统架构和工作流程如图5所示，其由离线和在线两个阶段组成。</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片6.png" style="zoom: 100%;">
</div>

<center>图5 CoDL的系统架构和工作流程</center>

<p>在离线阶段，CoDL设计了一个轻量的高效时延预测器用于指导在现阶段的算子切分。在线阶段包含算子分割器和算子协同执行器两个模块，算子分割器用于找出最优算子分割方案，其使用多维数据分割和算子链两种技术得到最优方案。算子分割器首先通过多维数据分割找到每个算子的最优分割维度（H，OC）和分割比作为基础方案。基于分割方案，使用算子链技术将算子组成链状，使得连上的算子不需要共享数据。算子协同执行器基于分割方案在处理器上协同运行工作负载，并针对不同处理器使用处理器友好的数据类型。如图6，CoDL在CPU和GPU间共享数据，将GPU友好型数据转化为CPU友好型数据交给CPU处理，之后CPU和GPU并行执行一条算子链上的算子。最终，CPU的推理结果被转换回GPU友好型数据和GPU的推理结果合并。</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片7.png" style="zoom: 100%;">
</div>

<center>图6 一个算子链的协同执行</center>

<h3 id="3-1多友好型数据共享"><a href="#3-1多友好型数据共享" class="headerlink" title="3.1多友好型数据共享"></a>3.1多友好型数据共享</h3><h4 id="3-1-1多维数据分割"><a href="#3-1-1多维数据分割" class="headerlink" title="3.1.1多维数据分割"></a>3.1.1多维数据分割</h4><p>在张量的不同维度上进行分割会产生不同的性能影响，图7展示了在OC和H维度上进行张量分割的情况。虽然在H维度上进行分割可以减小数据共享量（模型权重是固定不变的，可以预分配），但相较于OC维度上的分割，在H和W较小时可能会导致较低的处理器利用率（图8）。因此，分割的维度应该由每个算子的形状决定。CoDL的多维数据分割基于提出的时延预测器，可以通过给定的输入算子设置、分割方案预测并行执行的总时延。基于预测的时延找到DL模型每个算子的最优分割维度和分割比。CoDL针对每个算子预测不同分割方案的总时延，预测时延最小的方案的分割维度将被选择。</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片8.png" style="zoom: 100%;">
</div>

<center>图7 沿（a）OC（b）H进行数据分割示意</center>

<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片9.png" style="zoom: 80%;">
</div>

<center>图8 不同张量尺寸下CPU+GPU相较于单CPU执行的加速</center>

<h4 id="3-1-2算子链"><a href="#3-1-2算子链" class="headerlink" title="3.1.2算子链"></a>3.1.2算子链</h4><p>为了减少数据同步的次数，该文提出算子链技术，如图9，数据只需要在链上的开始和结束的算子上进行同步，其余算子只需使用本地数据。</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片10.png" style="zoom: 70%;">
</div>

<center>图9 算子链示意</center>

<p>虽然算子链可以有效减小数据同步的开销，但算子链越长需要padding的数据尺寸越大，将会造成更大的计算量，如图10所示，当算子链过长时，总时延可能反而会增大。</p>
<div align="center">
    <img src="/2022/10/13/CoDL%EF%BC%9AEfficient%20CPU-GPU%20Co-execution%20for%20Deep%20Learning%20Inference%20on%20Mobile%20Devices/图片11.png" style="zoom: 70%;">
</div>

<center>图10 有无算子链的时延对比</center>

<p>为了寻找能够最好地平衡数据同步和计算开销的算子链，该文提出了一个greedy-like算法。</p>
<h3 id="3-2-非线性并行执行时延预测"><a href="#3-2-非线性并行执行时延预测" class="headerlink" title="3.2 非线性并行执行时延预测"></a>3.2 非线性并行执行时延预测</h3><p>数据分割和算子链技术都依赖于算子协同执行的时延预测，然而现有系统无法实现准确且轻量的时延预测，主要由于</p>
<blockquote>
<p>1）没有考虑数据共享的开销；</p>
<p>2）由于忽视了应用平台的知识，预测器无法既准确又轻量。</p>
</blockquote>
<p>本文准确且轻量的时延预测器通过以下方法实现。</p>
<blockquote>
<p>1）引入所有数据共享的开销，<script type="math/tex">T=T_{trans}+T_{map}+T_{psync}+max(T_{comp}^{cpu},T_{comp}^{gpu})</script>；</p>
<p>2）通过分析性地对由平台特征引起的非线性延迟响应建模，降低学习的难度。基于对非线性延迟响应的分析，该文建立了如下时延预测的模型</p>
<script type="math/tex; mode=display">
T_{kernel}=\lceil\frac{Size_{output}}{Size_{block}\cdot Core ＃} \rceil \cdot \lceil\frac{Size_{block}}{Size_{basicUnit}} \rceil \cdot t_{basicUnit}</script><p>由于非线性已经被提取，只需使用轻量的线性回归模型学习给定处理器执行一个基本单元的时延即可。</p>
</blockquote>
<h2 id="4-Comments"><a href="#4-Comments" class="headerlink" title="4. Comments"></a>4. Comments</h2><p>本文提出了一个在移动设备的CPU和GPU上协同执行模型推理的系统架构和方法，许多方法的提出基于作者对大量实验现象的观察。通过联系实验现象和系统基本特性，该文实现了针对于移动设备的准确且轻量的时延预测。同时，该文数据分割和算子链的设计也具有启发意义。</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/10/20/Neurosurgeon/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Neurosurgeon：Collaborative Intelligence Between the Cloud and Mobile Edge</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/10/10/Numpy%E5%9F%BA%E7%A1%80/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Numpy基础</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
    <div class="valine-container">
        <script 
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script >
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'AIhtvUXrzUWmPIOmYNjrGExW-gzGzoHsz',
                    appKey: 'e4HGIfsWiHCnIXco4g7xtuAA',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: 'Add your comments',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Sun Hao';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('false') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2022</span> -
            
            2022
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Sun Hao</a>
            
        </div>
        
            <script async 
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme
            &nbsp;
            <a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.8</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-up-right-and-down-left-from-center"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Background-amp-Motivation"><span class="nav-text">1.Background &amp; Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Contributions"><span class="nav-text">2. Contributions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Design-Details"><span class="nav-text">3.Design Details</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1%E5%A4%9A%E5%8F%8B%E5%A5%BD%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB"><span class="nav-text">3.1多友好型数据共享</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2"><span class="nav-text">3.1.1多维数据分割</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2%E7%AE%97%E5%AD%90%E9%93%BE"><span class="nav-text">3.1.2算子链</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C%E6%97%B6%E5%BB%B6%E9%A2%84%E6%B5%8B"><span class="nav-text">3.2 非线性并行执行时延预测</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Comments"><span class="nav-text">4. Comments</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block-tools.js"></script>





<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
