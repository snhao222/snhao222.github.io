<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Sun Hao">
    
    <title>
        
            深度学习方法探析——卷积神经网络 |
        
        SnSpace
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/Slogo.svg">
    
<link rel="stylesheet" href="/fontawesome/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/regular.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"snhao222.github.io","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","logo":"/images/Slogo.svg","favicon":"/images/Slogo.svg","avatar":"/images/HeadImage.svg","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"S  n  S  p  a  c  e","font_color":null,"hitokoto":{"enable":false}},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block_tools":{"enable":true,"style":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.8"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/Slogo.svg">
                </a>
            
            <a class="logo-title" href="/">
               SnSpace
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">深度学习方法探析——卷积神经网络</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/HeadImage.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Sun Hao</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-10-10 10:30:00</span>
        <span class="mobile">2022-10-10 10:30</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/Learning-Materials/">Learning Materials</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h2 id="1-卷积神经网络的组成"><a href="#1-卷积神经网络的组成" class="headerlink" title="1. 卷积神经网络的组成"></a>1. 卷积神经网络的组成</h2><h2 id="1-1-卷积-Convolution"><a href="#1-1-卷积-Convolution" class="headerlink" title="1.1 卷积 (Convolution)"></a>1.1 卷积 (Convolution)</h2><h4 id="1-1-1-卷积运算"><a href="#1-1-1-卷积运算" class="headerlink" title="1.1.1 卷积运算"></a>1.1.1 卷积运算</h4><p>在数字图像处理中，我们用到了一种边缘检测算子，图1为一种垂直边缘检测的过程。依次在图像上圈出9个单元，将检测算子中的每个对应单元与圈出的单元相乘，最后将所有乘积结果相加，作为一个输出。依次移动框选区域，直至对整个图像进行运算。从输出图像可以看出，该运算过程检测出了图像中的垂直边缘，这个运算的过程就可以理解为卷积神经网络中最基本的卷积运算。使用不同的算子可以对图像中的不同边缘进行检测，甚至是45°、75°等特殊边缘，在边缘检测领域也曾提出过Sobel、Scharr等算子，其性能根据应用场景有所差别。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片1.png" style="zoom: 100%;">
</div>

<center>图1 数字图像处理中垂直边缘检测过程</center>

<p>卷积神经网络中的卷积运算，与上述操作的不同之处在于：卷积神经网络将算子中的9个固定的值当做9个参数来进行训练，如此便能得到任一种需要的算子，而不是只有固定的一种。卷积神经网络通常将这个算子称为过滤器，或卷积核。</p>
<h4 id="1-1-2-Padding"><a href="#1-1-2-Padding" class="headerlink" title="1.1.2 Padding"></a>1.1.2 Padding</h4><p>如果我们有一个n×n的图像，使用f×f的过滤器进行卷积，得到的输出图像维度为(n-f+1)×(n-f+1)。图1中的例子是对6×6的图像使用3×3的过滤器进行卷积，得到了4×4的输出。这会导致两个缺点：1）每次对图像进行卷积操作后，图像都会缩小；2）图像边缘的像素只在少数卷积运算中被使用，这导致了图像边缘的许多信息丢失。<br>为了解决这些缺点，Padding操作在图像的边缘填充一些数据，此时，输出的图像维度变为(n+2p-f+1)×(n+2p-f+1)，其中，p为padding操作增加的层数。例如，在图1中的原始图像上加上1层数据，变为8×8的图像，经过卷积运算后，输出为6×6的图像，与原始图像大小相同。<br>Padding操作通常有两种选择：Valid卷积和Same卷积。Valid卷积指不对原始图像进行填充，输出维度为(n-f+1)×(n-f+1)的图像；Same卷积指对图像进行填充，输出维度为(n+2p-f+1)×(n+2p-f+1)的图像，并使其与原始图像大小相等。</p>
<h4 id="1-1-3-卷积步长"><a href="#1-1-3-卷积步长" class="headerlink" title="1.1.3 卷积步长"></a>1.1.3 卷积步长</h4><p>在进行卷积操作时，还有一个重要的参数要进行选择：卷积步长(stride)。卷积步长指过滤器每次在图像上移动的格数。设置卷积步长后，输出的图像维度为<script type="math/tex">\lfloor\frac{n+2p-f}{s}+1\rfloor\times\lfloor\frac{n+2p-f}{s}+1\rfloor</script> ，其中，s为卷积的步长。</p>
<h4 id="1-1-4-三维卷积"><a href="#1-1-4-三维卷积" class="headerlink" title="1.1.4 三维卷积"></a>1.1.4 三维卷积</h4><p>彩色图像有R、G、B三个通道，它的维度不再是之前二维的n×n，变为三维的n×n×3，之前的卷积操作也应相应地变为三维卷积。三维卷积采用一与原图像通道数相同的三维过滤器进行卷积，如图2所示。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片2.png" style="zoom: 100%;">
</div>

<center>图2 三维卷积过程</center>

<p>三维卷积的过程为：将三维过滤器与原图像进行逐层二维卷积，并将得到的三层数据按位置相加，得到最终的二维输出。可能有一个过滤器是用来检测水平边缘的，但还想同时检测图像的其他特征。这时就可以增加过滤器的数量，每个过滤器负责检测一个特征，如图3所示，最终输出的通道数与过滤器的个数相等。也就是说，要检测多少特征，就会有多少个通道输出。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片3.png" style="zoom: 100%;">
</div>

<center>图3 多特征三维卷积</center>

<h4 id="1-1-5-卷积网络"><a href="#1-1-5-卷积网络" class="headerlink" title="1.1.5 卷积网络"></a>1.1.5 卷积网络</h4><p>单层卷积神经网络的前向传播过程如图4所示，可与普通的神经网络前项传播类比。卷积操作可以看做原来的特征权重<script type="math/tex">W</script>所做的操作，对每个滤波器卷积后得到的输出加上相应的偏差<script type="math/tex">b</script>后，通过一个非线性激活函数<script type="math/tex">g(z)</script>输出。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片4.png" style="zoom: 100%;">
</div>

<center>图4 卷积神经网络前向传播过程</center>

<p>现将卷积神经网络中<em>l</em>层各阶段的维度总结到表1中。</p>
<center><b>表1 卷积神经网络l层各阶段的维度</b></center>

<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片5.png" style="zoom: 100%;">
</div>

<p>其中，<script type="math/tex">n_H^{[l]}=\lfloor\frac{n_H^{[l-1]}+2p^{[l]}-f^{l}}{s^{[l]}}+1\rfloor,n_H^{[l]}=\lfloor\frac{n_W^{[l-1]}+2p^{[l]}-f^{l}}{s^{[l]}}+1\rfloor</script>。若有m个数据输入，则输出<script type="math/tex">A^{[l]}</script>的维度为<script type="math/tex">m\times n_H^{[l]}\times n_W^{[l]}\times n_C^{[l]}</script> 。</p>
<h4 id="1-1-6-卷积的优势"><a href="#1-1-6-卷积的优势" class="headerlink" title="1.1.6 卷积的优势"></a>1.1.6 卷积的优势</h4><p>与普通神经网络相比，采用卷积的神经网络主要有两个优势：参数共享和稀疏连接。<br>1) 参数共享<br>在使用普通的神经网络处理大量的特征时，由于两层的节点全部紧密相连，特征矩阵W中的参数个数为两层节点数的乘积，这可能有上千万的数量级。而使用卷积运算，无论前后两层有多少数据，需要训练的参数都只有过滤器的大小。这是由于，一个特征检测器如果适用于图片的某个区域，那么它也可能适用其他区域，而不需要额外训练其他特征检测器，做到参数的共享。<br>2) 稀疏连接<br>稀疏连接指每个输出都只与过滤器包含的范围有关，而与其他输入特征无关。<br>神经网络通过参数共享和稀疏连接两种机制减少参数，以此预防过拟合。同时，这使得卷积神经网络具有平移不变的属性。即使图像移动了几个像素，但其仍然有相似的特征，通过参数共享可以获得同样的输出标记，从而增强网络的鲁棒性。</p>
<h3 id="1-2-池化-Pooling"><a href="#1-2-池化-Pooling" class="headerlink" title="1.2 池化 (Pooling)"></a>1.2 池化 (Pooling)</h3><p>卷积神经网络除了有卷积层外，通常还使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。池化操作通常可分为两种类型：最大池化和平均池化。池化操作和卷积操作类似，可以使用一个过滤器，根据设定的步长和padding值对原图像进行运算。最大池化进行的操作是将该过滤器范围内的数据最大值进行输出，平均池化进行的操作是对过滤器范围内的数据求平均值作为输出。<br>对最大池化可以如下理解：若在图像的某个区域检测到了某个特征，池化输出在该部分会有一个较大的值。虽然，池化层作为卷积神经网络的一部分，但它没有任何需要调整的参数，一旦设定好f和s，其就是一个固定操作。池化的常用参数为<script type="math/tex">f = s = 2</script>，这可以使上一层的长和宽都减小一倍。</p>
<h3 id="1-3-全连接层-Fully-Connected"><a href="#1-3-全连接层-Fully-Connected" class="headerlink" title="1.3 全连接层 (Fully Connected)"></a>1.3 全连接层 (Fully Connected)</h3><p>全连接层的操作如图5所示，FC1将前面卷积池化后得到的数据进行展平，之后就与普通的深层神经网络相同，通过参数<script type="math/tex">W</script>和<script type="math/tex">b</script>进行前向传播，最后通过softmax层或sigmoid函数输出。由于两个全连接层中的节点紧密相连，这就是所谓的“全连接”。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片6.png" style="zoom: 100%;">
</div>

<center>图5 全连接层</center>

<h2 id="2-经典卷积神经网络"><a href="#2-经典卷积神经网络" class="headerlink" title="2. 经典卷积神经网络"></a>2. 经典卷积神经网络</h2><h3 id="2-1-LeNet-5"><a href="#2-1-LeNet-5" class="headerlink" title="2.1 LeNet-5"></a>2.1 LeNet-5</h3><p>LeNet-5是在1998年被提出的，一个LeNet的示例如图6所示。由于LeNet提出时主要用于处理灰度图像，这里采用一32×32×1的图像作为输入。LeNet的网络形式为：先卷积层和池化层交替，最后由几个全连接层输出预测结果。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片7.png" style="zoom: 100%;">
</div>

<center>图6 LeNet-5示例</center>

<h3 id="2-2-Alexnet"><a href="#2-2-Alexnet" class="headerlink" title="2.2 Alexnet"></a>2.2 Alexnet</h3><p>在一张227×227像素的图片上采用Alexnet网络的示例如7所示。Alexnet和LeNet非常相似，但Alexnet要大得多，LeNet有大约6万个参数，AlexNet包含约6000万个参数。因此，Alexnet表现得比LeNet更出色。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片8.png" style="zoom: 100%;">
</div>

<center>图7 Alexnet示例</center>

<h3 id="2-3-VGG-16"><a href="#2-3-VGG-16" class="headerlink" title="2.3 VGG-16"></a>2.3 VGG-16</h3><p>VGG-16是一种专注于构建卷积层的网络，它的一大优点是简化了神经网络结构，其示例如图8所示。VGG-16中的16指在这个网络中共包含16个卷积层和全连接层，虽然它规模很大，包含约1.38亿个参数，但其具有相当规整的结构：几个卷积层后接一个池化层，并且每次卷积的过滤器数量成倍增长，每次池化操作都将图像的大小缩减一倍。随着网络的加深，图像大小逐渐减小，深度逐渐增加。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片9.png" style="zoom: 100%;">
</div>

<center>图8 VGG-16示例</center>

<h2 id="3-先进的卷积神经网络结构"><a href="#3-先进的卷积神经网络结构" class="headerlink" title="3. 先进的卷积神经网络结构"></a>3. 先进的卷积神经网络结构</h2><h3 id="3-1-ResNet"><a href="#3-1-ResNet" class="headerlink" title="3.1 ResNet"></a>3.1 ResNet</h3><p>ResNet全称为Residual Networks，意为残差网络。ResNet是由残差块组成的网络，一个残差块如图9所示，残差块将<script type="math/tex">a^{[l]}</script>跨过计算<script type="math/tex">a^{[l+1]}</script>送至下一层，此时，<script type="math/tex">a^{[l+2]}</script>就变成</p>
<div align="right">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片10.png" style="zoom: 67%;">
</div>

<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片11.png" style="zoom: 100%;">
</div>

<center>图9 残差块</center>

<p>普通网络（Plain Network）在比较深时可能会出现梯度消失和梯度爆炸的问题，影响网络的性能，而残差网络可以很好地应对深度较大的网络，残差网络所做的事就是将浅层的信息传递到更深层的网络中去，可能远比一两层多。当网络层数很多时，如果为了应对梯度消失和梯度爆炸，对网络使用正则化，在深层的<script type="math/tex">W^{[l]}</script>会十分接近0，为了方便起见，<script type="math/tex">b^{[l]}</script>设为0，将(1)式展开为</p>
<div align="right">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片12.png" style="zoom: 67%;">
</div>

<p>在很深的层<script type="math/tex">l+2</script>上，将<script type="math/tex">W^{[l+2]}</script>当做0看待，(2)式变为</p>
<div align="right">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片13.png" style="zoom: 67%;">
</div>

<p>其中，由于激活函数采用ReLu，故经过激活函数后得到<script type="math/tex">a^{[l]}</script>，实现了信息从浅层到深层的传递，因此，可以训练更深层的网络，而不降低网络的效率。值得注意的是，残差网络因为采用网络的跳跃连接，为了保证维度合适，采用了很多same卷积。</p>
<h3 id="3-2-Google-Inception网络"><a href="#3-2-Google-Inception网络" class="headerlink" title="3.2 Google Inception网络"></a>3.2 Google Inception网络</h3><p>在构建卷积神经网络时，我们常常需要决定很多超参数，比如过滤器的大小、是否需要池化层等等。Inception网络所做的事就是，让网络代替人去做这些选择，虽然网络变得复杂，但网络表现可以得到提高。Inception模块如图10所示，它将多种操作得到的结果堆叠起来，为了保证维度相符，全部采用same卷积。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片14.png" style="zoom: 100%;">
</div>

<center>图10 Inception模块</center>

<p>这里采用了一种1×1的卷积形式，现对其进行分析。对一28×28×192的输入数据直接应用5×5的same卷积，如图11(a)所示。其总共要进行28×28×32×5×5×192≈1.2亿次乘法运算。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片15.png" style="zoom: 100%;">
</div>

<center>图11 有无瓶颈层卷积对比</center>

<p>图11(b)为采用了瓶颈层的卷积，第一次卷积操作进行了28×28×16×192≈240万次乘法运算，第二次卷积操作进行了28×28×32×5×5×16≈1000万次乘法运算，加起来共约1240万，仅为原来的十分之一。采用1×1卷积的原因，我认为是1×1卷积不会对原图像的特征起到影响，但却起到了压缩规模的作用，通过后续的卷积运算还可以保持原来的效果。<br>将许多Inception模块组合起来就形成了GoogLeNet网络，如图12所示。网络中存在一些分支，它们起到一些调整的作用，使隐藏层也参与特征计算，防止网络发生过拟合。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片16.png" style="zoom: 100%;">
</div>

<center>图12 GoogLeNet网络</center>

<h2 id="4-目标检测"><a href="#4-目标检测" class="headerlink" title="4. 目标检测"></a>4. 目标检测</h2><h3 id="4-1-目标定位"><a href="#4-1-目标定位" class="headerlink" title="4.1 目标定位"></a>4.1 目标定位</h3><p>目标分类只需要输出一个预测值即可，但目标定位不仅要完成分类，还要确定目标在图像中的位置，并标记出来，如图13所示。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片17.png" style="zoom: 100%;">
</div>

<center>图13 目标定位</center>

<p>目标分类只需要softmax层输出每个类别的概率即可，目标定位问题需要对该层的输出进行更改，增加一些辅助定位的参数，修改后的输出为</p>
<div align="right">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片18.png" style="zoom: 67%;">
</div>

<p>其中，<script type="math/tex">p_c</script>用来标记图片中是否包含要检测的对象，<script type="math/tex">b_x</script>、<script type="math/tex">b_y</script>表示目标的中心点坐标，<script type="math/tex">b_h</script>、<script type="math/tex">b_w</script>表示目标的高度和宽度，<script type="math/tex">c</script>为目标的类别，0表示未检测到该目标。当<script type="math/tex">p_c</script>为1时，代价函数将所有参数考虑进去；当<script type="math/tex">p_c</script>为0时，仅考虑<script type="math/tex">p_c</script>的准确度。</p>
<h3 id="4-2-基于滑动窗口的目标检测"><a href="#4-2-基于滑动窗口的目标检测" class="headerlink" title="4.2 基于滑动窗口的目标检测"></a>4.2 基于滑动窗口的目标检测</h3><p>比较简单的滑动窗口目标检测过程为：选择一种大小的窗口放在图像的初始位置，裁切下窗口中的图片，送入卷积神经网络中进行预测。依次移动滑动窗口，直至遍历整张图片。然后再改变窗口大小，重复上述过程，总有一个窗口可以识别到目标。但这种方法滑动窗口很慢，并且运算量巨大。<br>为了解决这一问题，可以使用滑动窗口的卷积实现。首先，需要将卷积神经网络中的所有层都转化为卷积操作，也就是要将全连接层转化为卷积层，图14 (a)为一个卷积层转化为全连接层的过程，将其转化为卷积层只需采用大小相同的过滤器对其进行卷积操作，得到1×1的维度，如图14 (b)所示。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片19.png" style="zoom: 100%;">
</div>

<center>图14 全连接层转化为卷积层</center>

<p>假设一个模型的滑动窗口大小为14×14×3，每次滑动窗口裁切后进行运算的过程如图15 (a)所示。在如图15(b)所示的16×16图片运用14×14的窗口进行卷积运算要进行4次，可以发现产生了许多重复的计算。<br>滑动窗口的卷积实现直接对16×16×3的图片应用原卷积操作，第一个滑动窗口涉及到的计算区域在图15(b)中用绿色标出，可以看到，对第一个滑动窗口的运算只体现在了输出的2×2×4模块的左上角。同理，其余三次运算体现为另外三个角落上。因此，只需对原图进行一次卷积神经运算就可以得到运算4次滑动窗口的效果，减少了很多运算。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片20.png" style="zoom: 100%;">
</div>

<center>(a)对滑动窗口大小区域运行卷积神经网络</center>

<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片21.png" style="zoom: 100%;">
</div>

<center>(b)滑动窗口的卷积实现</center>

<center>图15 普通滑动窗口和滑动窗口的卷积实现</center>



<h3 id="4-3-YOLO-You-Only-Look-Once-算法"><a href="#4-3-YOLO-You-Only-Look-Once-算法" class="headerlink" title="4.3 YOLO (You Only Look Once)算法"></a>4.3 YOLO (You Only Look Once)算法</h3><h4 id="4-3-1-Bounding-Box预测"><a href="#4-3-1-Bounding-Box预测" class="headerlink" title="4.3.1 Bounding Box预测"></a>4.3.1 Bounding Box预测</h4><p>采用滑动窗口的目标检测虽然能够检测到目标，但那些边框没办法完美匹配目标的位置。Bounding Box预测是YOLO算法中用于目标分类和定位的方法，它可以精确预测目标的位置。如图16所示，Bounding Box将图片分割成若干部分，每个部分对应一个与(4)式相同的label，图中的输出为9×9×k (k为单个label的长度)。<br>在训练时，喂给卷积神经网络图像，并将对应的label作为监督学习目标进行学习，目标仅属于中心点所在的格子。由于采用了滑动窗口的卷积实现，不用对每个格子单独进行一次运算，而是对整张图片进行一次卷积就可以输出所有预测值，减少了计算量，使得YOLO可以用于实时目标检测。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片22.png" style="zoom: 100%;">
</div>

<center>图16 Bounding Box预测</center>

<h4 id="4-3-2-非极大值抑制-Non-Max-Suppression"><a href="#4-3-2-非极大值抑制-Non-Max-Suppression" class="headerlink" title="4.3.2 非极大值抑制 (Non-Max Suppression)"></a>4.3.2 非极大值抑制 (Non-Max Suppression)</h4><p>当运行目标检测算法时，可能目标位于不同格子中的部分被各格子识别为中心点在其中，这将导致一个目标的多次识别，非极大值抑制做的就是防止目标的多次识别。<br>它首先找出概率最大的矩形，视其为检测到目标，然后将与其交并比较大的矩形抑制掉。然后再找剩下概率最大的矩形，抑制掉与其交并比大的矩形，如此重复，直到遍历所有矩形。</p>
<h4 id="4-3-3-Anchor-Boxes"><a href="#4-3-3-Anchor-Boxes" class="headerlink" title="4.3.3 Anchor Boxes"></a>4.3.3 Anchor Boxes</h4><p>前述操作只能在每个格子里检测一个目标，但如图17所示的情况会出现多个目标归属于同一格的情况，使用Anchor Boxes可以实现在一个格子里检测多个目标。</p>
<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片23.png" style="zoom: 100%;">
</div>

<center>图17 一格包含多个目标示意</center>

<div align="center">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片24.png" style="zoom: 100%;">
</div>

<center>图18 Anchor boxes</center>

<p>Anchor boxes的思路是这样的：在图17的情况中，我们可以预先设定两个Anchor boxes，如图18所示，实际情况可能需要设定更多的Anchor boxes。这种情况下输出的label就不能和 (4)式相同了，应更改为</p>
<div align="right">
    <img src="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/图片25.png" style="zoom: 80%;">
</div>

<p>其将 (4)式重复了2遍，如果设定更多Anchor boxes，则需要重复更多次数。<br>在训练时，需要将目标分配到所在格子内与之交并比更大的Anchor box项内，每个Anchor box项应是独立的，不受其他项的影响。<br>YOLO算法的流程为：使用卷积神经网络对图像进行推理后，每个格子里都会得到与Anchor boxes数量相等的项。我们需要先去除神经网络预测不存在对象的格子中的方框，此时剩下的方框中的多个Anchor boxes项可能都会识别到同一目标，再对剩下的格子应用非极大值抑制，得到真正的目标位置。</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/10/10/Numpy%E5%9F%BA%E7%A1%80/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Numpy基础</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/10/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%8E%A2%E6%9E%90%E2%80%94%E2%80%94%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E5%92%8C%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习方法探析——超参数调试和多分类模型</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
    <div class="valine-container">
        <script 
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script >
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'AIhtvUXrzUWmPIOmYNjrGExW-gzGzoHsz',
                    appKey: 'e4HGIfsWiHCnIXco4g7xtuAA',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: 'Add your comments',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Sun Hao';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('false') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2022</span> -
            
            2022
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Sun Hao</a>
            
        </div>
        
            <script async 
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme
            &nbsp;
            <a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.8</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-up-right-and-down-left-from-center"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%84%E6%88%90"><span class="nav-text">1. 卷积神经网络的组成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E5%8D%B7%E7%A7%AF-Convolution"><span class="nav-text">1.1 卷积 (Convolution)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-1-%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97"><span class="nav-text">1.1.1 卷积运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-2-Padding"><span class="nav-text">1.1.2 Padding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-3-%E5%8D%B7%E7%A7%AF%E6%AD%A5%E9%95%BF"><span class="nav-text">1.1.3 卷积步长</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-4-%E4%B8%89%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="nav-text">1.1.4 三维卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-5-%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-text">1.1.5 卷积网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-6-%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-text">1.1.6 卷积的优势</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E6%B1%A0%E5%8C%96-Pooling"><span class="nav-text">1.2 池化 (Pooling)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82-Fully-Connected"><span class="nav-text">1.3 全连接层 (Fully Connected)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">2. 经典卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-LeNet-5"><span class="nav-text">2.1 LeNet-5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Alexnet"><span class="nav-text">2.2 Alexnet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-VGG-16"><span class="nav-text">2.3 VGG-16</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%85%88%E8%BF%9B%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">3. 先进的卷积神经网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-ResNet"><span class="nav-text">3.1 ResNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Google-Inception%E7%BD%91%E7%BB%9C"><span class="nav-text">3.2 Google Inception网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-text">4. 目标检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D"><span class="nav-text">4.1 目标定位</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-%E5%9F%BA%E4%BA%8E%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-text">4.2 基于滑动窗口的目标检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-YOLO-You-Only-Look-Once-%E7%AE%97%E6%B3%95"><span class="nav-text">4.3 YOLO (You Only Look Once)算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-1-Bounding-Box%E9%A2%84%E6%B5%8B"><span class="nav-text">4.3.1 Bounding Box预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-2-%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6-Non-Max-Suppression"><span class="nav-text">4.3.2 非极大值抑制 (Non-Max Suppression)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-3-Anchor-Boxes"><span class="nav-text">4.3.3 Anchor Boxes</span></a></li></ol></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block-tools.js"></script>





<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



</body>
</html>
